\documentclass[12pt]{report}
\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
%\usepackage[familydefault,light]{Chivo}
\usepackage[T1]{fontenc}
\usepackage{csquotes}
\usepackage{graphicx}
\usepackage[onehalfspacing]{setspace}
\usepackage[a4paper, left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm]{geometry}
\usepackage{tikz}
\usepackage{aeguill}
\usepackage{scalefnt}
\usepackage{url}
\usepackage{hyperref}
\usepackage[figure]{hypcap}
\usepackage{fancyhdr}
\usepackage{verbatim}
\usepackage[printonlyused, nohyperlinks]{acronym}
\usepackage[extendedfeature=title]{scrextend}


%\bibliographystyle{abbrvdin}
\title{Vorhersage von Hotlinenutzung mit sensiblen Anrufszenarien}
\subtitle{Analyse der Telefonhotline zu Gewalt gegen Frauen in Brasilien 'Ligue 180'}
\author{Chiara Vogt Melian}
\date{\today}
\newtheorem{causal_model_definition}{Definition}[subsubsection] %TODO Theorem/Definition 

\begin{document}
	\maketitle
	\thispagestyle{empty}
	\newpage
	\pagenumbering{Roman}
	\setcounter{page}{2}
	\begin{spacing}{1}
		\chapter*{Abstract} 
		\addcontentsline{toc}{section}{Abstract}
		\renewcommand{\abstract}{}
		\abstract
	\end{spacing}
	%\newpage
	\begin{spacing}{1}
		\chapter*{Anmerkungen} 
		\addcontentsline{toc}{section}{Anmerkungen}
		%\renewcommand{\anmerkungname}{}	
		Die wörtlichen Zitate auf Englisch wurden aus Gründen der Nachvollziehbarkeit mit dem Übersetzer deepl.com übersetzt. 	
	\end{spacing}
	\newpage
	\begin{spacing}{1}
		
		\tableofcontents
	\end{spacing}
	\newpage
	
	\begin{spacing}{1}
		\chapter*{Abbildungsverzeichnis} 
		\addcontentsline{toc}{section}{Abbildungsverzeichnis}
		\renewcommand{\listfigurename}{}
		\listoffigures
	\end{spacing}
	\newpage
	\chapter*{Tabellenverzeichnis} 
	\addcontentsline{toc}{section}{Tabellenverzeichnis} 
	\renewcommand{\listtablename}{}
	\listoftables % Tabellenverzeichnis
	\footnote{Alle Tabellen wurden eigenständig erstellt, siehe \emph{R}-Code}  %TODO Anmerkung zu Tabellen überarbeiten
	\newpage
	\chapter*{Symbolverzeichnis} 
	\addcontentsline{toc}{section}{Symbolverzeichnis} %TODO Überarbeitung Symbolverzeichnis
	%Sortieren nach Auftreten im Text
	\begin{table}[h] \begin{center} \begin{tabular}{|lll|} \hline 
				& \textbf{Symbol} & \textbf{Bedeutung} \\ \hline \hline
				& $H_0 \colon$ &Nullhypothese\\ 
				& $H_1 \colon$ &Alternativhypothese\\
				& $\mathbf{I}_n\colon$ &Einheitsmatrix der Dimension $n$\\
				& $k$ &Anzahl der unabhängigen Variablen\\
				& $L(\cdot)$ &Plausibilitätsfunktion bzw. Likelihood-Funktion\\ 
				& $\ell(\cdot)$ & logarithmische Plausibilitätsfunktion bzw. log-Likelihood-Funktion\\ 
				& $n\colon$& Stichprobenumfang\\
				& $p$ &Anzahl der Regressionsparameter\\
				& $R^2\colon$ & Bestimmtheitsmaß\\ 
				& $\overline{R}^2\colon$ & adjustiertes Bestimmtheitsmaß\\ 
				& $\mathbf{X}\colon$& Versuchsplanmatrix \\ 
				& $\beta_1,\beta_2, \ldots, \beta_k\colon$& unbekannte Regressionsparameter\\ 
				& $ G_\Phi(\vartheta)$& Gütefunktion\\ 
				\hline
	\end{tabular} \end{center} \end{table}
	\newpage
	\chapter*{Abkürzungsverzeichnis} 
	\addcontentsline{toc}{section}{Abkürzungsverzeichnis} %TODO Abkürzungsverzeichnis überarbeitet?
	\begin{spacing}{0.1}
		\begin{acronym}		
			\acro{dag}[DAG]{gerichteter azyklischer Graph}
			\acro{kg}[KG]{Knowledge Graph}		
			\acro{owl}[OWL]{Web Ontology Language}
			\acro{rdf}[RDF]{Resource Description Framework}
			\acro{uri}[URI]{Universal Resource Identifier}
			\acro{xml}[XML]{eXtensible Markup Language}
		\end{acronym}
	\end{spacing}	
	\newpage
	\clearpage
	\pagenumbering{arabic}
	\setcounter{page}{1} 
	\newpage
	\pagestyle{fancy}
	\fancyhead[L]{Chiara Vogt Melian}
	\fancyhead[R]{\textbf{Zeitreihenanalyse der Telefonhotline 'Ligue 180'}}
	
	\renewcommand{\headrulewidth}{0.1 pt}
	\renewcommand{\footrulewidth}{0 pt}
	
	\chapter{Einleitung}
	
	Warum ist das wichtig?
	Strategiepapier der Lei raussuchen, wo steht "dass die Profissionais geschult werden müssen"
	Deswegen sinnvoll erstmal zu suchen wofür sensibilisert werden soll. 
	Warum diese Methode?
	
	
	\section{Potenzial der Prediction Models für} %TODO Wofür steht diese Arbeit besipielhaft?
	\section{Fragestellung}
	Im nächsten Abschnitt wird erläutert, welche Schwerpunkte die Analyse des Datensatzes \textit{Ligue 180} beinhaltet. In Form von Forschungsfragen und Hypothesen leiten diese inhaltlich durch die Arbeit. 
	\section{Gliederung der Arbeit}
	\subsection{Forecasting der Anrufquote}
	Die Arbeit wird drei Themenbereiche abdecken und die Analyse des Datensatzes dabei jeweils um eine Komponente erweitern. Der erste Teil der Analyse betrachtet die Menge der Anrufe, und hat zum Ziel vorherzusagen, wann wie viele Anrufe getätigt werden, um eine ausreichende Deckung der Hotline sicherzustellen. Dafür werden die Methoden der Time Series Analysis und des Forecasting genutzt. \\
	Auf deutsch nennt sich der Bereich der Methode Entwicklungsprognose oder Zeitreihenanalyse und gehört zu dem Bereich der quantitativen Prognosetechniken \cite[S. 11]{Vogel.2015}.
	\subsection{Clusteranalyse der Nutzer:innengruppen}
	\subsection{Raumcluster und Zusammenhänge}
	\chapter{Grundlagen} 
	\section{Verwandte Arbeiten (Influential Research)} 
	%TODO die Frau mit dem Github-Projekt und der Datenanalyse da drin
	\section{Erwartete Ergebnisse}
	\chapter{Vorbereitung der Daten}
	\section{Der 'Ligue 180'-Datensatz}
	\subsection{Eckdaten der Hotline 'Ligue 180' anhand des Jahres 2019}
	Der Datensatz zeigt die Menge an Anzeigen die über die Hotline  'Ligue 180' gestellt wurden. 	Die Telefonhotline 'Ligue 180' ist eine kostenlose Hotline, welche über Telefon sowie über Messenger und eine Website verfügbar ist. Sie ist der Hauptkanal zwischen dem Ministerium für Frauen, Familie und Menschenrechte\footnote{auf Portugiesisch: \textit{Ministério da Mulher, da Família e dos Direitos Humanos}} und der Bevölkerung \cite[S. 12]{BalancoLigue180.2020}. Die Nummer kann anonym gewählt werden und das Personal besteht ausschließlich aus Frauen.\\
	Die Telefonhotline hat die Aufgaben:
	\begin{itemize}
		\item Anzeigen von Verletzungen von Frauenrechten aufzunehmen,
		\item der Weiterleitung der Anliegen an die zuständigen Stellen,
		\item das Monitoring der Prozesse,
		\item Frauen in Gewaltsituationen zu beraten und
		\item diese Frauen an spezialisierte Einrichtungen weiterzuleiten,
		\item Verbreitung von Informationen über die Rechte der Frauen,
		\item Beratung über Aktionen, Programme, Kampagnen, Dienste zum Schutz, zur Verteidigung und zur Rechenschaftslegung der Rechte der Frauen, die auf Bundes-, Landes- und Gemeindeebene zur Verfügung stehen \cite[S. 12, 19]{BalancoLigue180.2020}.
	\end{itemize} 
	
	Aus dem Report der Hotline für 2019 ist zu entnehmen, dass für das Jahr 2019 96\% der Anrufe in unter 20 Sekunden angenommen werden konnten. Im Durchschnitt gab es eine Wartezeit von 4 Sekunden in der Warteschlange und die Anrufdauer betrug im Durchschnitt 220 Sekunden. Nur 1,91\% der Anrufenden brachen den Anruf vor der Beantwortung des Anrufs ab \cite[S. 12]{BalancoLigue180.2020}.\\
	Die abgefragten Informationen wurden im Juli 2019 aktualisiert und mit dem Formular FRIDA ( Formulário de Avaliação de Risco e Proteção à Vida) standardisiert \cite[S. 13]{BalancoLigue180.2020}.\\
	In 2019 wurden insgesamt 1.314.113 Anrufe angenommen, davon waren 6,50\% registrierte Anzeigen, 47,91\% Informationsanfragen und 45,59\% sonstige Anfragen, wie Lob, Anregungen, Beschwerden oder Streiche \cite[S. 14]{BalancoLigue180.2020}.\\
	Die Hotline kann auch aus dem Ausland angerufen werden; die Anrufe werden auf Portugiesisch, Englisch und Spanisch entgegengenommen \cite[S. 15]{BalancoLigue180.2020}. 
	%TODO noch was zu der Verteilung sagen im Vergleich zu allen Anrufen
	%TODO und zu der Entwicklung des Datensatzes
	\subsection{Der verwendete Datensatz}
	Die Daten sind aus einem durch die brasilianische Regierung zur Verfügung gestellten Datensatz des Ministeriums für Menschen- und Bürgerrecht\footnote{Übersetzung: Ministério dos Direitos Humanos e da Cidadania, URL: \url{https://www.gov.br/mdh/pt-br}, zuletzt aufgerufen am: 30.09.2024, 15:01 Uhr}. Der Datensatz beinhaltet die Meldungen von Gewalt gegen Frauen,  die bei der Hotline 'Ligue 180' eingegangen sind. Er besteht aus 17 einzelnen Datensätzen und erstreckt sich über die Jahre 2014 bis zum ersten Halbjahr 2024\footnote{Quelle der Daten: \url{https://www.gov.br/mdh/pt-br/acesso-a-informacao/dados-abertos/ligue180} und /url{https://dados.gov.br/dados/conjuntos-dados/central-de-atendimento-a-mulher--ligue-180} (aufgerufen am 02.10.2024, 07:08 Uhr).}. %TODO: das ist keine Fußnote sondern muss in die Quellen!--beides\\
	%TODO Balanco lesen und als Quelle einfügen, wichtige Punkte rausarbeiten
	Insgesamt enthalten alle Datensätze zusammen 2.406.112 Einträge; ab 2020 hat der Datensatz die gleiche Struktur und ergibt 1.681.161 Einträge mit 62 Kategorien. Diese Menge an Daten ist selbst bei einer großen Anzahl ungültiger Werte ausreichend für die maschinelle Verarbeitung.\\
	Durch das brasilianische Gesetz des Zugangs zu Informationen 12.527\footnote{\url{http://www.planalto.gov.br/ccivil_03/_ato2011-2014/2011/lei/l12527.htm} %TODO als Quelle
	(aufgerufen am 02.10.2024, 08:41 Uhr)} werden Leitlinien festgesetzt, die den Zugang zu staatlich erhobenen Daten ermöglichen. Dadurch kann auf den Datensatz 'Central de Atendimento à Mulher – Ligue 180' über das \textit{Portal der offenen Daten} zugegriffen werden\footnote{\url{https://dados.gov.br/dados/conjuntos-dados/central-de-atendimento-a-mulher--ligue-180} (aufgerufen am 02.10.2024, 08:48 Uhr)}.
	\section{Datenauswahl}
	Eine anfängliche Durchsicht der Einträge zeigt, dass nicht alle für eine Verarbeitung geeignet sind. Die Rohdaten haben eine Menge von 2.406.097 Einträgen, darin befinden sich ab 2020 Daten mit gleichem Key \textit{hash}\footnote{Für das erste Semester 2020 heißt der Key \textit{hash\_par\_vitima\_suspeito}.} und gleichem Timestamp. Diese wurden augenscheinlich mehrmals aufgenommen, um mehrere Tatschwerpunkte festzuhalten. In Tabelle \ref{tab:gleicher-hash} kann beispielhaft nachvollzogen werden, welche Unterschiede in Werten mit dem gleichen \textit{hash} zu finden sind. 
	Nach der Eliminierung dieser Duplikate verbleiben 1.069.407 Datenpunkte.\\	
	\begin {table}[ht] %TODO Tabelle hübsch machen
		\caption {hash: d2d9664e8a2fb21d0a441753b3532b3a (Vorkommen: 69)} \label{tab:gleicher-hash} 
		\centering
		\small
		\begin{tabular}{|l|l|}
		\hline
		'Profissão\_do\_suspeito' & 'CONSELHEIRO TUTELAR'\\
		\hline
		'violacao' & 'INTEGRIDADE>PATRIMONIAL>INDIVIDUAL'\\
		~ & 'INTEGRIDADE>FÍSICA>MAUS TRATOS'\\
		~ & 'INTEGRIDADE>PSÍQUICA>AMEAÇA ou COAÇÃO'\\
		~ & 'INTEGRIDADE>PSÍQUICA>CONSTRANGIMENTO' \\
		\hline
		'Motivação' & 'PARA FINS DE EXPLORAÇÃO DO TRABALHO.COMÉRCIO/ INDÚSTRIA'\\
		~ & 'EM RAZÃO DE CONDIÇÕES FÍSICAS, SENSORIAIS, INTELECTUAIS OU MENTAIS'\\
		~ & 'POR CONFLITO AGRÁRIO.QUILOMBOLAS'\\
		~ & ... \\
		~ & 'PARA FINS DE EXPLORAÇÃO SEXUAL' 'EM RAZÃO DA RELAÇÃO DE ENSINO'\\
		~ & 'POR CONFLITO AGRÁRIO.PESCA'\\
		~ & 'COM HUMILHAÇÃO' 'EM RAZÃO DA PROFISSÃO'\\
		~ & ...\\
		~ & 'DA COABITAÇÃO/ CONVIVÊNCIA FAMILIAR/ RELAÇÃO AFETIVA'\\
		~ & 'FOI PRATICADO POR DUAS OU MAIS PESSOAS'\\
		~ & 'PARA FINS DE EXPLORAÇÃO DO TRABALHO.DOMÉSTICO'\\
		~ & 'PARA FINS DE REMOÇÃO DE ÓRGÃOS/ TRÁFICO DE ÓRGÃOS'\\
		~ & 'EM PÚBLICO OU POR MEIO QUE FACILITE A DIVULGAÇÃO/ NO ÂMBITO DA INTERNET'\\
		~ & 'POR CONDUTAS EXCESSIVAS/ DESNECESSÁRIAS/ DESACONSELHADAS'\\
		~ & 'NA FORMA DE AUXÍLIO/INSTIGAÇÃO/INDUZIMENTO/INCITAÇÃO'\\
		~ & 'PARA FINS DE EXPLORAÇÃO DO TRABALHO.INFORMAL'\\
		~ & 'FALTA DE ACESSIBILIDADE.NOS MEIOS DE TRANSPORTE'\\
		~ & 'EM DESCUMPRIMENTO DE MEDIDA PROTETIVA' 'EM RAZÃO DO SEXO BIOLÓGICO'\\
		~ & 'RESULTANDO EM LESÃO SEGUIDA DE MORTE' 'RESULTANDO EM LESÃO LEVE'\\
		~ & 'NA FORMA CULPOSA' 'POR VIOLÊNCIA INSTITUCIONAL' 'COM FINS CORRETIVOS'\\
		~ & 'RESULTANDO EM LESÃO GRAVE'\\
		~ & 'DO AGRESSOR POSSUIR INFLUÊNCIA JUNTO ÀS AUTORIDADES LOCAIS'\\
		~ & 'NA RELAÇÃO FAMILIAR' 'EM RAZÃO DE CONFLITO DE IDEIAS'\\
		~ & 'EM RAZÃO DA RELIGIÃO' 'EM RAZÃO DE RAÇA/COR'\\
		~ & 'PARA FINS DE EXPLORAÇÃO DO TRABALHO.OUTROS'\\
		~ & 'PARA OBTENÇÃO DE BENEFÍCIO FINANCEIRO/ GANÂNCIA' 'EM RAZÃO DA IDADE'\\
		~ & 'POR CRIME AMBIENTAL.COM FINS DE EXTRATIVISMO.MINERAL'\\
		~ & 'POR CRIME AMBIENTAL.PESCA'\\
		~ & 'RESULTANDO EM UMA DEFICIÊNCIA EM RAZÃO DA VIOLÊNCIA'\\
		~ & 'EM RAZÃO DE ORIENTAÇÃO SEXUAL/ IDEOLOGIA DE GÊNERO'\\
		~ & 'POR CRIME AMBIENTAL.DE CAÇA' 'PARA FINS DE EXPLORAÇÃO DO TRABALHO.RURAL'\\
		~ & 'COM RESULTADO MORTE' 'EM RAZÃO DA ORIGEM'\\
		~ & 'POR MOTIVO VIL, TORPE, INSIDIOSO, CRUEL, À TRAIÇÃO, OU POR DINHEIRO'\\
		~ & 'EM RAZÃO DE SER MULHER' 'COM VÍTIMA EM SITUAÇÃO DE RUA'\\
		~ & 'FALTA DE ACESSIBILIDADE.NO ESPAÇO EDIFICADO'\\
		~ & 'PARA FINS DE ATIVIDADE ILÍCITA' 'RESULTANDO EM LESÃO GRAVÍSSIMA'\\
		~ & 'POR CRIME AMBIENTAL.COM FINS DE EXTRATIVISMO.VEGETAL' 'NA FORMA TENTADA'\\
		~ & 'POR CONFLITO AGRÁRIO.DE COMUNIDADES TRADICIONAIS'\\
		~ & 'POR CRIME AMBIENTAL.PARA EXPANSÃO AGROPECUÁRIA'\\
		~ & 'FALTA DE ACESSIBILIDADE.NA COMUNICAÇÃO'\\
		~ & 'EM RAZÃO DE SER COMUNICADOR SOCIAL'\\
		~ & 'EM RAZÃO DE QUAISQUER FORMAS DE DISCRIMINAÇÃO'\\
		~ & 'VALENDO-SE DA HOSPITALIDADE' 'POR CONFLITO AGRÁRIO.INDÍGENAS'\\
		~ & 'FALTA DE ACESSIBILIDADE.NOS SISTEMAS DE COMUNICAÇÃO OU DE TECNOLOGIA DA INFORMAÇÃO'\\
		~ & 'POR CONFLITO AGRÁRIO DE CAÇA' 'PARA FINS DE ADOÇÃO'\\
		\hline
	\end{tabular}
	\caption {Should be a caption}

	\end {table}
	\subsubsection{Time Prediction Analysis}
	Für die Vorhersage der Menge der Anrufe wird ein neuer Datensatz
	geschaffen, der beinhaltet, wie viele Anrufe pro Stunde oder pro Tag getätigt werden.\\
	Für die stündliche Vorhersage werden die Datenpunkte gelöscht, die keinen Stundenwert enthalten. Das ergibt eine Menge von 40.926 Datenpunkten.\\
	Die Anrufe pro Tag ergeben nach der Bereinigung 3.652 Datenpunkte.\\
	Ursprüngliche Menge an Einträgen: 2406097 \\
	Einträge mit hash (2020-2023): 1739566\\
	Anzahl an einzigartigen hash: 402876\\
	Für den Datensatz mit Stunden: 1811098
	(Aussortieren der Daten ohne Stundenwert)\\
	Datensatz ohne Duplikate: 1069407\\
	Datensatz Anrufe pro Stunde: 40926 (Auswahlkriterium ist die Spalte hash. Diese darf jeweils nur einmal vorhanden sein)\\
	Datensatz Anrufe pro Tag: 3652 (Auswahlkriterium hash)\\
	%TODO Aussortierdiagramm wie in der Masterarbeit
	\begin{figure}
		\centering
		\includegraphics[width=0.7\linewidth]{screenshot001}
		\caption{}
		\label{fig:screenshot001}
	\end{figure}
	\subsubsection{Umgang mit Fehlenden Daten}
	%TODO Diagramm mit fehlenden Daten einfügen
	\textit{Fehlende Daten in hourly\_call\_volume}\\	
	Die fehlende Uhrzeit in der Zeitreihe mit stündlichen Daten ergibt insgesamt sechs Monate fehlender Daten in 2020. \\
	\begin {table} [ht]%TODO Tabelle hübsch machen\\
	\label{tab:fehlende-tage} 
	\centering
	\begin{tabular}{|l|l|}
		\hline
		2020-01-31  & 31\\
		2020-02-29  & 29\\
		2020-03-31  & 31\\
		2020-04-30  & 30\\
		2020-05-31  & 31\\
		2020-06-30  & 30\\
		\hline
	\end{tabular}
	\caption {Should be a caption} %TODO
	\end {table}
	%TODO Umgang damit, dass so eine große Lücke ist
	\begin{figure}
		\centering
		\includegraphics[width=1\linewidth]{screenshot003}
		\caption{}
		\label{fig:screenshot003}
	\end{figure}
	\textit{Fehlende Daten in daily\_calls}\\
	Im Datensatz daily\_calls verzeichnen 45 Tage keine Anrufe. Diese sind in einem Block vom 26. Januar 2014 bis 03. April 2014 (37 Tage) zu finden und in einem zweiten Block vom 24. Dezember 2019 bis 31. Dezember 2019 (8 Tage). Da die Nullwerte jeweils als Block vorzufinden sind, ist es wahrscheinlicher, dass fälschlicherweise keine Daten erhoben wurden bzw. in dem online verfügbaren Datensatz nicht vorhanden sind. Weniger wahrscheinlich ist, dass in diesen Zeiträumen keine Anzeigen stattfanden; insbesondere für den zweiten Block, der Weihnachten und Silvester umspannt. Vorherige Forschungsergebnisse %TODO Quellen und Erklärung vielleicht als Fußnote
	haben gezeigt, dass gerade Familienfeiern zu einem Anstieg häuslicher Gewalt führen. Außerdem finden sich Zusammenfassungen mit Statistiken zu diesem Datensatz, hier werden Zahlen zu der allgemeinen Menge an Anrufen gezeigt, z.B. einem Anrufvolumen in 2014 von 1.348 pro Tag und 40.425 Gespräche pro Monat \cite[S. 5]{BalancoLigue180.2015}Aus dem Bericht lässt sich keine konkrete Zahl von Anzeigen pro Monat oder pro Tag ableiten, jedoch zeigen die Zahlen, dass es nicht der Fall ist, dass in den Zeiträumen keine Anzeigen getätigt wurden\cite{BalancoLigue180.2015, BalancoLigue180.2020}. \\
	Deshalb ist es wahrscheinlich, dass es in diesen Zeiträumen Anrufe gab %TODO und im Folgenden werden nach \cite{Atwan.2022} verschiedene Methoden ausprobiert, um die passendste Auffüllmethode zu wählen.
	
 \begin{figure}
		\centering
		\includegraphics[width=1\linewidth]{screenshot002}
		\caption{}
		\label{fig:screenshot002}
	\end{figure}
	Dezember 2019
	Nullwerte für März 2019: Daten sind für den Monat vorhanden im Balanco 2019, warum diese Daten nicht in der Statistik sind ist nicht klar.
	Dezember ist auffällig weil es vom 24. bis 31. ist: einerseits Vermutung, dass da besonders viele Anrufe sind wegen Feiertage, Alkohol, Familienstreit aka nicht null. Deswegen kann ich mir nicht vorstellen, dass die zu hatten. Vielleicht haben sie aber keine Anzeigen aufgenommen, aber dann funktionieren auch die Schutzmaßnahmen nicht. 
	
	%TODO Recherche warum an diesen Tagen keine Anrufe waren und umliegende DAten anschauen
	\subsubsection{Clusteranalyse von Nutzungsgruppen}
	%TODO Beschreiben der Vorbereitung des Datensatzes bei H2
	\subsection{Feature Vorbereitung}
	Der Datensatz enthält 62 verschiedene Kategorien. \\
	- Zusammenführen der Datensätze, inwieweit möglich? \\
	- Tabelle mit verschiedenen Kategorien \\
	- Tabelle mit Menge der Values\\
	- Zusammenführung von Values - Übersicht\\
	- Zusammenhangsgrafik der Kategorien (die vom Tablet) \\
	- Anhang mit Kategorien und Werten\\
	\subsubsection{H1}
	- Daten die zwischen leeren Tagen Monaten liegen bei df\_hourly?\\
	- hinzufügen der Ferientage: Ferientage eingetragen, mit Differenz: -1 bedeutet einen Tag nach Feiertag und +1 einen Tag vor Feiertag
	- Ergebnisse sind \ref{tab:differenz-zu-feiertagen}
	\begin {table} [ht]%TODO Tabelle hübsch machen
	\label{tab:differenz-zu-feiertagen} 
	\centering
	\begin{tabular}{|l|l|}
		\hline
		1    & 90\\
		2    & 90\\
		0    & 98\\
		-1    & 88\\
		3    & 88\\
		... & ~ \\
		-56    & 10 \\
		-57     & 10\\
		-58     & 10\\
		-59     & 10\\
		-60     & 10 \\  
		\hline
	\end{tabular}
	\caption {days\_to\_holiday for daily dataset from 2014 to 2023} %TODO
	\end {table}
	- Das gleiche für df\_daily gemacht
	\subsection{Feature Auswahl}
	\subsubsection{H1}
	-> Nullwerte für df\_hourly schon gezeigt\\
	
	- Daraus Schlussfolgerung welche Daten gewählt werden\\
	- Tabelle mit Nullwerten\\	
	- 
	\section{Künstliche Intelligenz} %Dieses Kapitel wird wahrscehinlich nirgends sinnvoll reinpassen
	\label{sec:ki}
	Die Künstliche Intelligenz ist das mit vielen verschiedenen Hoffnungen verbundene zukunftsweisendste Forschungfeld der Gegenwart. Die großen Hoffnungen und Erwartungen begründen sich auch in den vielfältigen Ansätzen und Techniken, die in den Bereich der künstlichen Intelligenz fallen \cite[S. 2]{Ege.2021b}. So gehört zum Bereich künstliche Intelligenz laut \cite[S. 2]{Ege.2021b}:
	\begin{itemize} \itemsep0pt
		\item die Logik, z.B. Aussagenlogik, Prädikatenlogik, Entscheidbarkeit,
		\item unsicheres Wissen und Schlussfolgerungen, z.B. Bayessche Netze, Fuzzy-Logik,
		\item Suchstrategien, z.B. uninformierte Suche, heuristische Suche,
		\item Wissensrepräsentationen, z.B. Ontologien und Semantic Web,
		\item Machine Learning, z.B. neuronale Netze und Deep Learning in Kombination von supervised und unsupervised Learning und Reinforcement Learning,
		\item Natural Language Processing,
		\item Computervision,
		\item Robotik.
	\end{itemize}	
	Bei den verschiedenen Ansätzen wird zwischen symbolischen und nicht-symbolischen unterschieden. Symbolische Ansätze bezeichnen Techniken und Ansätze des Maschinellen Lernens bei denen die Merkmale und Zusammenhänge von Mustern expliziert und repräsentiert sind. Das Verhalten dieser Techniken ist nachvollziehbar, kalkulierbar und interpretierbar. Zu diesen Techniken gehören Entscheidungsbäume, Ontologien, das Semantic Web und Wissensgraphen \cite[S. 9]{Ege.2021b}. Nicht-symbolische Ansätze speichern Wissen implizit. Dieses Wissen muss anhand großer Datensätze trainiert werden. Die Ergebnisse der Wissensrepräsentationen sind deshalb unvorhersehbar und manchmal auch nicht nachvollziehbar \cite[S. 9]{Ege.2021b}
	
	\chapter{Explorative Datenanalyse}
	Im folgenden Kapitel wird Anhand der Methoden in \cite{Walker.2024} %TODO Quellen
	erforscht, in welchem Zusammenhang die Daten miteinander stehen. 
	\section{Datenanalyse zu für H1 verwendeten Daten}
	\begin{figure}
		\centering
		\includegraphics[width=1\linewidth]{calls_daily}
		\caption[Menge der Anzeigen pro Tag von 2014 bis 2023]{Menge der aufgegebenen Anzeigen über die Hotline 'Ligue 180' von 2014 bis 2023}
		\label{fig:callsdaily}
	\end{figure}
	\begin{figure}
		\centering
		\includegraphics[width=1\linewidth]{calls_hourly}
		\caption[Menge der Anzeigen pro Tag von 2014 bis 2023]{Menge der aufgegebenen Anzeigen über die Hotline 'Ligue 180' von 2014 bis 2023}
		\label{fig:callshourly}
	\end{figure}
	
	\section{Datenmenge}
	Erste Fragen zu dem Datensatz aus \cite[S.77f.]{Walker.2024}.
	Die kleinste Einheit im Datensatz, also der unique identifier: hash
	Menge der Daten: Spalten x Reihe
	%TODO Tabelle mit Mengen
	Key categorical values and the frequencies of each value?
	%TODO Tabelle mit allen relevanten Variablen
	%TODO Tabelle mit Begründung warum andere Variablen nicht relevant sind
	Verteilung kontinuierlicher Variablen
	%TODO raussuchen
	%TODO Verteilung berechnen
	Zusammenhänge zwischen den einzelnen Variablen
	%TODO 
	Variablen mit Werten außerhalb des Erwartungsbereichs und fehlende Werte
	%TODO
	
	\section{Verständnis für Daten}
	"When working with time series, it is critical that you learn more about the data you are working with and how it relates to the problem you are attempting to solve. For example, when working with manufacturing or sales data, you cannot assume that an organization's working day is Monday to Friday or whether it uses the standard calendar year or fiscal year. You should also consider understanding any holiday schedule, annual shutdowns, and other matters related to the business operation." aus Atwan.2022 \textit{Time Series Analysis with Python Cookbook}.
	\section{Forecasting der Anrufquote}
	Anhand des Methodenbuchs \textit{Time Series Analysis and Forecasting} der Autoren \textsc{Montgomery, Jennings, Kulahci} 2015 \cite{Montgomery.2015} werden im folgenden die Schritte beschrieben, die für eine Analyse im Bereich Forecasting benötigt werden.\\
	\subsection{Data Collection and Cleaning}
	Zu Beginn ist es wichtig die vorhandenen verfügbaren Daten auf ihre Nützlichkeit zu prüfen. Es können Werte fehlen, Daten verfälscht sein oder jegliches anderes Datenproblem auftreten. Hier muss festgehalten werden, welche Daten weshalb genutzt werden \cite[14]{Montgomery.2015}. \\
	Außerdem sollten die Daten bestimmten Gütekriterien entsprechen, laut \cite[17]{Montgomery.2015} sind diese \textit{ \glqq accuracy, timeliness, completeness, reprensatativeness, and consistency\footnote{Übersetzung:\textit{\glqq Genauigkeit, Aktualität, Vollständigkeit, Repräsentativität und Konsistenz.\grqq }}.\grqq} Im folgenden Abschnitt wird geprüft, ob die Daten diese Kriterien erfüllen.
	\subsubsection{Accuracy}
	Die Genauigkeit misst die Nähe der abgebildeten Daten zu den Daten in der Realität. 
	\subsubsection{Timeliness}
	Die Daten sollten bei einem Forecasting in die Zukunft so aktuell wie möglich gehalten werden, um eine genaue Vorhersage sicherzustellen. 
	\subsubsection{Completeness}
	Die Vollständigkeit verlangt vom Datensatz, dass es keine Ausreißer und fehlenden Werte gibt. 
	\subsubsection{Representativeness}
	Die vorhandenen Daten sollten für die Fragestellung geeignet sein, beispielsweise ist es nicht sinnvoll, die Daten der Hotline zu verwenden, um im allgemeinen Vorherzusagen, wann Gewalt gegen Frauen in Brasilien geschieht.
	\subsubsection{Consistency}
	Dieses Gütekriterium verlangt Konsistenz innerhalb der Zeitreihe, nicht nur inhaltlich sondern auch Formate und die Bedeutung von Kategorien und die Struktur des Datensatzes.
	
	\subsection{Data Analysis}
	Im Vorbereitungsschritt der Datenanalyse werden ist es wichtig die Zeitreihe auch visuell aufzubereiten. Dadurch können saisonale Muster oder Trends erkannt werden\cite[14f.]{Montgomery.2015}. 
	Im Fall der vorliegenden Daten ergeben  sich starke Differenzen in den Aufzeichnungen zwischen den Jahren 2014 und 2023.\\
	%TODO Grafik mit Zeitreihe
	%*Analyse welchen Zeitraum man weshalb genommen hat
	Ein weiterer Teil der vorbereitenden Analyse sind die Berechnung der statistischen Kennzahlen, wie Sample Mean, Standardabweichung, Perzentile und Autokorrelationen.\\ %siehe Chapter 2 in Montgomery.2015
	Ebenfalls ist es sinnvoll potenzielle Ausreißer festzuhalten, um sie später auf ihre Passbarkeit zu prüfen. Diese Vorbereitungen sind wichtig um ein Gefühl für die Daten zu bekommen und die Ergebnisse besser einordnen zu können \cite[15]{Montgomery.2015}.\\
	
	\chapter{Vergleich der Zeitreihenvorhersagemodelle}
	Das SARIMA (Seasonal AutoRegressive Integrated Moving Average) Modell setzt sich aus 4 Bestandteilen zusammen. Diese sind das Autoregressive Model, das Moving Average Model, deren Integration und die saisonale Komponente. Diese vier Bestandteile werden im folgenden Abschnitt erläutert.
	\section{SARIMA Modell}
	Das SARIMA-Modell vereint verschiedene Vorhersagemethoden miteinander. Das Modell besteht aus den Komponenten:
	\begin{itemize}
		\item S - Seasonal
		\item AR - Autoregressive Model
		\item I - Integrated
		\item MA - Moving Average Model
	\end{itemize}
	\subsection{Anwendungsbereich}
	
	\subsection{Bestandteile des Modells}
	\subsubsection{Autoregressives Modell}
	Die Prognose durch ein Autoregressionsmodell wird durch die vorangegangenen Werte bestimmt. Die Variablen der Zeitreihe werden gegen sich selbst regressiert. Das kann mit folgender mathematischer Formel für alle autoregressiven Modelle \textbf{AR($p$) model} der Ordnung $p$ dargestellt werden:\\
	\begin{equation}
	y_{t} = c + \phi_{1}y_{t-1} + \phi_{2}y_{t-2} + \dots + \phi_{p}y_{t-p} + \varepsilon_{t}
	\end{equation} 
	Darin ist $y_{t}$ die Zeitreihe, $c$ ist der Durchschnitt der Veränderung von aufeinanderfolgenden Werten und $\varepsilon_{t}$ bezeichnet das weiße Rauschen \cite[Kapitel 8.1, 8.3]{Hyndman.May2018}.\\
	Autoregressive Modelle verlangen stationäre Daten. 
	\subsubsection{Moving Average Modell}
	In diesem Modell werden nicht die vergangenen Werten für die Vorhersage genutzt, sondern die vergangenen Vorhersagefehler mithilfe des gleitenden Durchschnits (Moving Average)\cite[Kapitel 8.4]{Hyndman.May2018}. Das Modell \textbf{MA($q$) model} wird mit folgender Formel dargestellt:\\
	\begin{equation}
		y_{t} = c + \varepsilon_t + \theta_{1}\varepsilon_{t-1} + \theta_{2}\varepsilon_{t-2} + \dots + \theta_{q}\varepsilon_{t-q}
	\end{equation}
	\subsubsection{Non-Seasonal ARIMA Modell}
	Das nicht saisonale ARIMA (AutoRegressive Integrated Moving Average) Modell ist die Kombination des AR und des MA Modells. Integration stellt hier das Gegenteil von Differenzierung dar \cite[Kapitel 8.5]{Hyndman.May2018}. Das ARIMA Modell wird mit folgender Formel beschrieben:
	\begin{equation}
		y'_{t} = c + \phi_{1}y'_{t-1} + \cdots + \phi_{p}y'_{t-p} + \theta_{1}\varepsilon_{t-1} + \cdots + \theta_{q}\varepsilon_{t-q} + \varepsilon_{t}
	\end{equation}
	Das \textbf{ARIMA($p,d,q$) model} hat die Parameter
	\begin{itemize}
		\item $p$ = Ordnung des autoregressiven Teils;
		\item $d$ = Grad der ersten Differenzenbildung;
		\item $q$ =	Ordnung des Teils des gleitenden Durchschnitts.
	\end{itemize}
	\subsubsection{Seasonal ARIMA Modell}
	Es ist möglich dem ARIMA Modell eine saisonale Komponente hinzuzufügen. Die saisonale Komponente wird durch einen weiteren Term in Großbuchstaben beschrieben. 
	Das Modell wird beschrieben mit:	
	\begin{equation}
		ARIMA (p, d, q) (P, D, Q)_m
	\end{equation}
	Der Parameter $m$ bezeichnet die Anzahl der Beobachtungen pro Jahr. Der Autor \cite[Kapitel 8.9]{Hyndman.May2018} benennt das Beispiel von ARIMA(1,1,1)(1,1,1)4, das die Formel 
	\begin{equation}
		(1 - \phi_{1}B)~(1 - \Phi_{1}B^{4}) (1 - B) (1 - B^{4})y_{t} =
		(1 + \theta_{1}B)~ (1 + \Theta_{1}B^{4})\varepsilon_{t}
	\end{equation}
	herbeiführt. Daran kann erkannt werden, dass die neu hinzugefügten saisonalen Terme mit den bestehenden Termen multipliziert werden. 
	
	\subsection{Voraussetzungen des Modells}
	Damit ein Datensatz in ein SARIMA Modell verarbeitet werden kann, muss dieser das Kriterium der Stationarität erfüllen. 
	\subsubsection{Stationarität}
	Stationarität bezeichnet die Eigenschaft, dass die Eigenschaften einer Zeitreihe, wie Mittelwert und Varianz über die Zeit konstant bleiben \cite[S. 26]{Vogel.2015}.
	Folgende drei Eigenschaften müssen erfüllt sein, damit ein Prozess als stationär (oder schwach stationär) bezeichnet werden kann:
	\begin{enumerate}
		\item \(\mu(t) =: \mu\) (der Mittelwert) hängt nicht von der Zeit \(t\) ab.
		\item \(\sigma^2(t) =: \sigma^2\) (die Varianz) hängt nicht von der Zeit \(t\) ab.
		\item \(\gamma(t_1, t_2) =: \gamma(t_2 - t_1)\) (die Autokovarianz) hängt nur von der Zeitdifferenz \(t_2 - t_1\) ab \cite[S. 26]{Vogel.2015}.
	\end{enumerate}
	\textbf{Definition}: Erfüllt ein stochastischer Prozess 2. Ordnung die Eigenschaften (1) bis (3), so heißt er schwach stationär \cite[S. 26]{Vogel.2015}. \\
	Der Mittelwert $\mu$ der Datenreihe verändert sich nicht, somit hat die Datenreihe keine Trends, also über die Zeit fallende oder steigende Werte. \\
	Die Varianz $\sigma^2$ bezeichnet die Entfernung der Werte um den Mittelwert (Streuung der Werte); auch diese bleibt konstant.\\
	Die Autokovarianz $\gamma(t_1, t_2)$ beschreibt den Zusammenhang zwischen zwei Werten in der Zeitreihe. Bei einer stationären Zeitreihe darf dieser Zusammenhang nur durch die Zeitdifferenz bestimmt werden \cite[S. 26]{Vogel.2015}. 
	Eine stationäre Zeitreihe sollte also zu jedem Zeitpunkt ähnlich aussehen. Jedoch kann eine solche Zeitreihe auch zyklische Muster haben, die aber keinem Trend folgen \cite[Kapitel 8.1]{Hyndman.May2018}.	
	\subsection{Auswahl der Parameter}
	Die Parameter $p, d, q$ und $P, D, Q$ sowie $m$ müssen ausgewählt werden, um das beste SARIMA Modell zu erstellen. 
	
	\subsubsection{Autocorrelation Function ACF und Partial Autocorrelation Function PACF}
	Für die Bestimmung der Parameter sind zwei Funktionen hilfreich: die Autocorrelation Function (ACF) und Partial Autocorrelation Function (PACF). Aus einer Zeitreihe ist es meist nicht möglich die Autokorrelation einer Zeitreihe herauszulesen, mithilfe der ACF und PACF-Plots kann das jedoch gelingen \cite[Kapitel 8.5]{Hyndman.May2018}. \\
	In einem ACF-Plot wird die Autokorrelation dargestellt, indem die Beziehung von $y_t$ zu $y_{t-k}$ entlang der Reihe von $k$ gezeigt wird. Damit die 
	
	\subsection{Bewertung und Überarbeitung des Modells}%TODO Das ist sicher für alle Modelle gleich -> anderes Kapitel
	
	\section{Hyperparameteroptimization}
	Fast alle Vorhersagemethoden braucht von außen festgelegte Parameter, um geeignete Vorhersagen zu modellieren. Diese festgelegten Parameter sind Hyperparameter. Um die zu finden, können verschiedene Methoden der Hyperparameteroptimierung angewendet werden. Klassischerweise wird dafür die Gittersuche (Gridsearch), die zufällige Suche (Random Search), die bayesische Optimierung oder durch Expertise und heuristische Annäherung händisch ausgewählte Parameter. 
	\subsubsection{Heuristische Annäherung an passende Parameter}
	\subsubsection{Optuna}
	
	\chapter{Methodik} %TODO jemand hat das Unterteilt in Entwurf, Implementierung und Evaluierung
	\section{Defining Modelling Objective}
	\section{Datenvorverarbeitung}
	In dem Leitfaden \textit{Data Preparartion for Machine Learning} beschreibt \cite{Brownlee.2020} die Datenvorbereitung als elementaren Bestandteil der Analyse. Er argumentiert, dass die Verarbeitungsalgorithmen seit Jahren bekannt sind, jedoch die evaluierten Datensätze die Innovation mitbringen, weswegen diese besonders gut verarbeitbar sein sollten \cite[14]{Brownlee.2020}. Demnach ist das,  was die Qualität der Studien ausmacht, nicht der ausgewählte Algorithmus, sondern die Verarbeitung der Daten von Rohdaten zu Daten für die maschinelle Verarbeitung \cite[9]{Brownlee.2020}. Dabei muss herausgefunden werden, wie die zugrunde liegende Struktur des Datensatz bestmöglich herausgearbeitet werden kann \cite[8]{Brownlee.2020}. Das ist abhängig davon, welcher Algorithmus verwendet werden soll, um das Modell zu erstellen \cite[12]{Brownlee.2020}. 
	\subsection{Vorverarbeitungsschritte}
	Je nach Algorithmus können irrelevante oder korrelierende Daten die Vorhersage des Modells verschlechtern. Die Wahl der Vorverarbeitung hängt zudem auch von dem vorliegenden Datensatz ab. Im Prozess des Feature Engineerings werden entscheidende Features, die das Design des Models mitbestimmen herausgearbeitet \cite[12]{Brownlee.2020}.\\	
	Bei der Wahl der Vorverarbeitungsschritte können zwei Es gibt den Ansatz durch das Modellieren herauszufinden, welche Schritte in der Datenvorverarbeitung notwendig sind. So können die Zusammenhänge der Daten beim Erstellen des Modells herausgearbeitet werden \cite[13]{Brownlee.2020}. Auf der anderen Seite gibt es die Möglichkeit, sich für jede Datenzeile zu überlegen, wie diese Aussehen müsste, um bestmöglich deren Charakter herauszuarbeiten \cite[13]{Brownlee.2020}. Der Autor plädiert dafür, eine Balance zwischen den beiden Ansätzen zu finden, da beide Ansätze mächtig seien und zu einer Ausarbeitung der zugrunde liegenden Struktur beitrügen \cite[13]{Brownlee.2020}.\\
	Entscheidend ist laut \cite[25ff.]{Brownlee.2020} ebenso die Reihenfolge der Vorverarbeitungsschritte. Der Autor benennt folgende Schritte als gängige Praxis: 
	\begin{itemize} \itemsep0pt
		\item Prepare Dataset
		\item Split Data
		\item Evaluate Model.
	\end{itemize}
	Diese Reihenfolge sieht er kritisch, da sie zu data leakage\footnote{Data leakage bedeutet, dass das Model Informationen erhält, die zu einem Vorteil für eine bessere Modellierung werden. Das können Testdaten sein, die den Trainingsdaten zur Verfügung stehen oder wenn Informationen aus der Zukunft der Vergagenheit zur Verfügung stehen \cite[93]{Zheng.2018}.} führen kann und somit das Modell beeinflussen kann \cite[26]{Brownlee.2020}. Ein Beispiel für data leakage findet sich in der Normalisierung einer Variable in der Skala von 0 bis 1. Dafür muss Minimum und Maximum aller Variablen identifiziert werden und somit erhält das Model Informationen über die globale Verteilung und somit über die Testdaten. Bei vielen Methoden, um Daten zu normalisieren und leere Felder zu füllen greift dieser Mechanismus.\\
	Aus diesem Grund plädiert \cite{Brownlee.2020} für diese Schritte, um die Daten vorzuverarbeiten:
	\begin{itemize} \itemsep0pt
		\item Split Data
		\item Fit data preparation on Training Dataset
		\item Apply Data Preparation to Train and Test Datasets
		\item Evaluate Models.
	\end{itemize}
	Nicht nur die Vorbereitung der Daten sollte nur mit dem Trainingsdatensatz erfolgen; dieser Ansatz sollte die gesamte Modellierung umfassen, wie Feature Selection, Feature Engineering und  Dimensionality Reduction \cite[27]{Brownlee.2020}.\\
	Diese Vorannahmen führen dazu, dass der erste Schritt der Vorverarbeitung die Einteilung in Test- und Trainingsdaten ist.
	\subsubsection{Unterteilung der Daten in Trainings und Testdaten}
	Einladen der Daten als Panda-Dataframe\\
	Verbinden der Jahre 2021 bis 2023\\
	Nutzen der Methode train\_test\_split von sklearn.model\_selection\\
	\subsubsection{Grundlagen der Datenbereinigung} 
	
	
	\section{Auswertungsmethoden}
	\chapter{Results}
	\section{Structure Learning}
	\section{Auswertungskriterien}
	\chapter{Discussion}
	\section{Preparation of Data}
	\section{Structure Learning}
	\section{Auswertungskriterien}	
	\chapter{Limitations}	
	\chapter{Conclusion}
	
	\newpage
	\clearpage
	
	
	
	\chapter*{Bibliography}
	\addcontentsline{toc}{section}{Bibliography}
	\bibliographystyle{abbrvdin}
	%\renewcommand{\refname}{}
	\bibliography{Literatur}
	
	\newpage
	
	
	\appendix %Anhang
	\pagestyle{empty}
	\pagenumbering{Roman}
	\setcounter{page}{1}
	\chapter{Appendix}
	
	\chapter*{Erklärung der Urheberschaft}
	
	Ich erkläre hiermit an Eides statt, dass ich die vorliegende Arbeit
	ohne Hilfe Dritter und ohne Benutzung anderer als der angegebenen
	Hilfsmittel angefertigt habe; die aus fremden Quellen direkt oder
	indirekt übernommenen Gedanken sind als solche kenntlich gemacht. Die
	Arbeit wurde bisher in gleicher oder ähnlicher Form in keiner anderen
	Prüfungsbehörde vorgelegt und auch noch nicht veröffentlicht.
	
	\vspace{4cm}
	
	\hspace{2cm} Ort, Datum \hfill Unterschrift \hspace{2cm}
	
	
	
\end{document}